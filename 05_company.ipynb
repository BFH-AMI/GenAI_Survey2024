{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Company"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3a1b51306766a85"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fefd48c9c4d386ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from metadata import QUESTION_ID_MAP\n",
    "from plotting import plot_single_cat, plot_multi_cat, plot_wordcloud"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dfe13dc0b0abd60",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98e8443e5bb35bc5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/base1.csv', index_col='resp_id')\n",
    "start_id = 23\n",
    "end_id = 41\n",
    "df = df[df.columns[start_id:end_id]]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62efcc397d29cfc3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i,q in enumerate(list(QUESTION_ID_MAP.keys())[start_id:end_id]):\n",
    "    print(f\"Q{i+1+start_id}: {q}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbec0ce4b48dbe89",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (*) Q24 - Q29: Does your company currently utilize generative AI technology within internal processes, as part of a product or service, or in any other capacity?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6dd0218f83d3632"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "multi_cat_df = pd.DataFrame(data={\n",
    "    'internal_process': df.Q24,\n",
    "    'products_services': df.Q25,\n",
    "    'other_capacities': df.Q26,\n",
    "    'no': df.Q27,\n",
    "    'dont_know': df.Q28,\n",
    "    'other': df.Q29,\n",
    "})\n",
    "multi_cat_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53cb27f3b737df59",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "multi_cat_df.loc[multi_cat_df['dont_know'] == \"Yes\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d338238eba0bae95",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Yes, we use generative AI technology within our internal processes\",\n",
    "    \"Yes, we incorporate generative AI technology into our products or services\",\n",
    "    \"Yes, we use generative AI technology in other capacities\",\n",
    "    \"No, our company does not currently use generative AI technology\",\n",
    "    \"I don’t know\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "yes_counts = [\n",
    "    int(multi_cat_df[multi_cat_df.internal_process == \"Yes\"].internal_process.count()),\n",
    "    int(multi_cat_df[multi_cat_df.products_services == \"Yes\"].products_services.count()),\n",
    "    int(multi_cat_df[multi_cat_df.other_capacities == \"Yes\"].other_capacities.count()),\n",
    "    int(multi_cat_df[multi_cat_df.no == \"Yes\"].no.count()),\n",
    "    int(multi_cat_df[multi_cat_df.dont_know == \"Yes\"].dont_know.count()),\n",
    "    int(multi_cat_df.other[~multi_cat_df.other.isna()].count())\n",
    "]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    print(f\"{labels[i]}: {yes_counts[i]}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nOther\")\n",
    "for o in multi_cat_df.other[~multi_cat_df.other.isna()]:\n",
    "    print(o)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a2bf8e47d87525",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels[0] = labels[0].replace(' within', '\\nwithin')\n",
    "labels[1] = labels[1].replace(' technology', '\\ntechnology')\n",
    "labels[2] = labels[2].replace(' technology', '\\ntechnology')\n",
    "labels[3] = labels[3].replace(' use', '\\nuse')\n",
    "\n",
    "labels[0] = \"Internal\\nprocess\"\n",
    "labels[1] = \"Products &\\nservices\"\n",
    "labels[2] = \"Other\\ncapacities\"\n",
    "labels[3] = \"No usage\"\n",
    "\n",
    "plot_multi_cat(labels, yes_counts, total_answers=len(df), save_path=\"figures/q24_29.png\", figsize=(9, 7))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfeb1f3bb3d37192",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q30: In case your company does use generative AI, which tasks or applications is it primarily utilized for?\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a707ced3f51ec1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "translator = GoogleTranslator(source='auto', target='en')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8ef250916304107",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6052352eaca1e46f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number answers: {df.Q30[~df.Q30.isna()].count()}\")\n",
    "print()\n",
    "q30_text_answers = []\n",
    "for row in df[~df.Q30.isna()].iterrows():\n",
    "    resp_id = row[0]\n",
    "    answer = row[1].Q30\n",
    "    q30_text_answers.append(translator.translate(answer))\n",
    "    \n",
    "q30_text = \" \".join(q30_text_answers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f696e7e6d932c0f4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_wordcloud(q30_text, save_path=\"figures/q30.png\", width=1200, height=600, max_words=50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbf9eae9e631f5ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for q in q30_text_answers:\n",
    "    print(q)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8aed6c3f8c181b89",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (*) Q31 - Q37 In case your company doesn't use generative AI, what are the main reasons for not adopting this technology?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4a18fc52481be67"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "multi_cat_df = pd.DataFrame(data={\n",
    "    'awareness_lack': df.Q31,\n",
    "    'cost': df.Q32,\n",
    "    'expertise_lack': df.Q33,\n",
    "    'concern_reliability': df.Q34,\n",
    "    'no_use': df.Q35,\n",
    "    'dont_know': df.Q36,\n",
    "    'other': df.Q37,\n",
    "})\n",
    "multi_cat_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a5e367a0cb7063",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Lack of\\nawareness\",\n",
    "    \"Cost\",\n",
    "    \"Lack of\\n expertise\",\n",
    "    \"Concerns about\\nreliability &\\naccuracy\",\n",
    "    \"Sees no use\",\n",
    "    \"Don’t know\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "yes_counts = [\n",
    "    int(multi_cat_df[multi_cat_df.awareness_lack == \"Yes\"].awareness_lack.count()),\n",
    "    int(multi_cat_df[multi_cat_df.cost == \"Yes\"].cost.count()),\n",
    "    int(multi_cat_df[multi_cat_df.expertise_lack == \"Yes\"].expertise_lack.count()),\n",
    "    int(multi_cat_df[multi_cat_df.concern_reliability == \"Yes\"].concern_reliability.count()),\n",
    "    int(multi_cat_df[multi_cat_df.no_use == \"Yes\"].no_use.count()),\n",
    "    int(multi_cat_df[multi_cat_df.dont_know == \"Yes\"].dont_know.count()),\n",
    "    int(multi_cat_df.other[~multi_cat_df.other.isna()].count())\n",
    "]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    print(f\"{labels[i]}: {yes_counts[i]}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\nOther\")\n",
    "for o in multi_cat_df.other[~multi_cat_df.other.isna()]:\n",
    "    print(o)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6b4930b48ab187d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_multi_cat(labels, yes_counts, total_answers=len(df), save_path=\"figures/q31_37.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4511db22f1bb719e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q38 + Q39: Do you see potential to integrate generative AI into your company's processes in the future? + Other"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "622bff449bce6617"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "orig_q = df.Q38.copy()\n",
    "other_q = df.Q39.copy()\n",
    "combined_q = orig_q.copy()\n",
    "\n",
    "print(len(other_q[~other_q.isna()]))\n",
    "for other in other_q[~other_q.isna()]:\n",
    "    print(other)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35082abc9cafe697",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_single_cat(df['Q38'], drop_nans=True, custom_order=[2,0,3,1], ticks_rotation=0, horizontally=False, save_path=\"figures/q38_q39.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e798f5e4f94bbaa",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q40: In what areas of your work do you see potential benefits from using generative AI technology?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "744d5fe5867c4ee1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number answers: {df.Q40[~df.Q40.isna()].count()}\")\n",
    "print()\n",
    "q40_text_answers = []\n",
    "for row in df[~df.Q40.isna()].iterrows():\n",
    "    resp_id = row[0]\n",
    "    answer = row[1].Q40\n",
    "    q40_text_answers.append(translator.translate(answer))\n",
    "    \n",
    "q40_text = \" \".join(q40_text_answers)\n",
    "\n",
    "plot_wordcloud(q40_text, save_path=\"figures/q40.png\", width=1200, height=600, max_words=50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5733b25bd8101174",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Q41: Are there some additional things you would like to share?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f27bebe3a5c3793"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number answers: {df.Q41[~df.Q41.isna()].count()}\")\n",
    "print()\n",
    "q41_text_answers = []\n",
    "for row in df[~df.Q41.isna()].iterrows():\n",
    "    resp_id = row[0]\n",
    "    answer = row[1].Q41\n",
    "    if any(x in answer for x in (\"Zugrössli\", \"yänu\", \"siech\")):\n",
    "        continue\n",
    "    q41_text_answers.append(translator.translate(answer))\n",
    "    \n",
    "q41_text = \" \".join(q41_text_answers)\n",
    "\n",
    "plot_wordcloud(q41_text, save_path=\"figures/q41.png\", width=1200, height=600, max_words=50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a6045c6010954d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "33c5fa322f40af7d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
